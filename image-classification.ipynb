{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T14:10:47.895931Z",
     "iopub.status.busy": "2023-04-16T14:10:47.895471Z",
     "iopub.status.idle": "2023-04-16T14:10:52.669298Z",
     "shell.execute_reply": "2023-04-16T14:10:52.668022Z",
     "shell.execute_reply.started": "2023-04-16T14:10:47.895888Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from albumentations import Compose, Resize, HorizontalFlip, Normalize, RandomBrightnessContrast, \\\n",
    "    RandomGamma, GaussNoise, ShiftScaleRotate, ImageCompression, CoarseDropout\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T14:10:52.672011Z",
     "iopub.status.busy": "2023-04-16T14:10:52.671277Z",
     "iopub.status.idle": "2023-04-16T14:10:53.021193Z",
     "shell.execute_reply": "2023-04-16T14:10:53.019638Z",
     "shell.execute_reply.started": "2023-04-16T14:10:52.671969Z"
    }
   },
   "outputs": [],
   "source": [
    "path = '/kaggle/input/vk-made-sports-image-classification'\n",
    "\n",
    "train = pd.read_csv(os.path.join(path, 'train.csv'))\n",
    "train['path'] = train.image_id.apply(lambda x: os.path.join(path, 'train', x.split('.')[0] + '.jpeg'))\n",
    "\n",
    "test = pd.read_csv(os.path.join(path, 'test.csv'))\n",
    "test['path'] = test.image_id.apply(lambda x: os.path.join(path, 'test', x.split('.')[0] + '.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T14:10:53.023406Z",
     "iopub.status.busy": "2023-04-16T14:10:53.022981Z",
     "iopub.status.idle": "2023-04-16T14:10:53.054361Z",
     "shell.execute_reply": "2023-04-16T14:10:53.052742Z",
     "shell.execute_reply.started": "2023-04-16T14:10:53.023343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46514481-2d8b-4d49-8991-012e1bfd34f6.jpeg</td>\n",
       "      <td>swimming</td>\n",
       "      <td>/kaggle/input/vk-made-sports-image-classificat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ec66e513-adac-4a30-b6a9-3d647ee6e46b.jpeg</td>\n",
       "      <td>greco-Roman_wrestling</td>\n",
       "      <td>/kaggle/input/vk-made-sports-image-classificat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4d60732e-d680-4bfd-9067-70ff8137f537.jpeg</td>\n",
       "      <td>running</td>\n",
       "      <td>/kaggle/input/vk-made-sports-image-classificat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93327011-8e3d-4f0d-849d-a26ddaf6488b.jpeg</td>\n",
       "      <td>football</td>\n",
       "      <td>/kaggle/input/vk-made-sports-image-classificat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b6853478-48c1-48b2-b104-74903730c831.jpeg</td>\n",
       "      <td>sailing</td>\n",
       "      <td>/kaggle/input/vk-made-sports-image-classificat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    image_id                  label  \\\n",
       "0  46514481-2d8b-4d49-8991-012e1bfd34f6.jpeg               swimming   \n",
       "1  ec66e513-adac-4a30-b6a9-3d647ee6e46b.jpeg  greco-Roman_wrestling   \n",
       "2  4d60732e-d680-4bfd-9067-70ff8137f537.jpeg                running   \n",
       "3  93327011-8e3d-4f0d-849d-a26ddaf6488b.jpeg               football   \n",
       "4  b6853478-48c1-48b2-b104-74903730c831.jpeg                sailing   \n",
       "\n",
       "                                                path  \n",
       "0  /kaggle/input/vk-made-sports-image-classificat...  \n",
       "1  /kaggle/input/vk-made-sports-image-classificat...  \n",
       "2  /kaggle/input/vk-made-sports-image-classificat...  \n",
       "3  /kaggle/input/vk-made-sports-image-classificat...  \n",
       "4  /kaggle/input/vk-made-sports-image-classificat...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T14:10:54.332278Z",
     "iopub.status.busy": "2023-04-16T14:10:54.331844Z",
     "iopub.status.idle": "2023-04-16T14:10:54.340926Z",
     "shell.execute_reply": "2023-04-16T14:10:54.339494Z",
     "shell.execute_reply.started": "2023-04-16T14:10:54.332241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45373, 3), (19446, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Распределение по классам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T14:10:56.822942Z",
     "iopub.status.busy": "2023-04-16T14:10:56.822505Z",
     "iopub.status.idle": "2023-04-16T14:10:56.866688Z",
     "shell.execute_reply": "2023-04-16T14:10:56.864976Z",
     "shell.execute_reply.started": "2023-04-16T14:10:56.822906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "alpinism                 1858\n",
       "archery                   982\n",
       "arm_wrestling            1392\n",
       "badminton                1140\n",
       "basketball               2519\n",
       "boating                  1753\n",
       "boxing                   1801\n",
       "fencing                  1421\n",
       "football                 2150\n",
       "golf                     1393\n",
       "greco-Roman_wrestling    1298\n",
       "gymnastics               1415\n",
       "handball                 1509\n",
       "hockey                   2151\n",
       "horseback_riding         1568\n",
       "javelin-throwing          811\n",
       "pole_vault               1047\n",
       "rugby                    1967\n",
       "running                  1991\n",
       "sailing                  1181\n",
       "sambo                    1264\n",
       "skating                  1957\n",
       "ski_race                 1335\n",
       "surfing                  1420\n",
       "swimming                 1283\n",
       "taekwondo                1110\n",
       "tennis                   1735\n",
       "velo                     1216\n",
       "volleyball               1856\n",
       "water_polo                850\n",
       "Name: image_id, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df['label'].isna()].groupby('label').image_id.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Итог - классы распределены относительно равномерно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для нормализации значений посчитаю mean и std по датасету"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T12:02:56.760256Z",
     "iopub.status.busy": "2023-04-16T12:02:56.759403Z",
     "iopub.status.idle": "2023-04-16T12:02:56.768118Z",
     "shell.execute_reply": "2023-04-16T12:02:56.767371Z",
     "shell.execute_reply.started": "2023-04-16T12:02:56.760220Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_mean_std(filepath: str) -> dict:\n",
    "    image = cv2.imread(filepath)\n",
    "    img_mean = np.array([np.mean(image[:,:,2]), np.mean(image[:,:,1]), np.mean(image[:,:,0])])\n",
    "    img_std = np.array([np.std(image[:,:,2]), np.std(image[:,:,1]), np.std(image[:,:,0])])\n",
    "    return {\n",
    "        'mean': img_mean,\n",
    "        'std': img_std,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T12:03:10.325869Z",
     "iopub.status.busy": "2023-04-16T12:03:10.325484Z",
     "iopub.status.idle": "2023-04-16T12:03:10.330366Z",
     "shell.execute_reply": "2023-04-16T12:03:10.329285Z",
     "shell.execute_reply.started": "2023-04-16T12:03:10.325833Z"
    }
   },
   "outputs": [],
   "source": [
    "filepaths = [p for p in df[~df.label.isna()]['path'].values]\n",
    "\n",
    "with Pool(12) as p:\n",
    "    samples = list(tqdm(iterable=p.imap_unordered(get_mean_std, filepaths), total=len(filepaths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T12:03:10.484859Z",
     "iopub.status.busy": "2023-04-16T12:03:10.484496Z",
     "iopub.status.idle": "2023-04-16T12:03:10.489595Z",
     "shell.execute_reply": "2023-04-16T12:03:10.488546Z",
     "shell.execute_reply.started": "2023-04-16T12:03:10.484825Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_ = list(pd.DataFrame(samples)['mean'].mean() / 255)\n",
    "std_ = list(pd.DataFrame(samples)['std'].mean() / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T12:03:10.827451Z",
     "iopub.status.busy": "2023-04-16T12:03:10.827083Z",
     "iopub.status.idle": "2023-04-16T12:03:10.835572Z",
     "shell.execute_reply": "2023-04-16T12:03:10.834243Z",
     "shell.execute_reply.started": "2023-04-16T12:03:10.827416Z"
    }
   },
   "outputs": [],
   "source": [
    "# mean_ = [0.4740159605137972, 0.46442562157460615, 0.4598326978744472]\n",
    "# std_ = [0.25182542253038637, 0.2385384052725654, 0.24216548789726602]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T12:03:11.026472Z",
     "iopub.status.busy": "2023-04-16T12:03:11.025789Z",
     "iopub.status.idle": "2023-04-16T12:03:11.033778Z",
     "shell.execute_reply": "2023-04-16T12:03:11.032689Z",
     "shell.execute_reply.started": "2023-04-16T12:03:11.026437Z"
    }
   },
   "outputs": [],
   "source": [
    "class Imagewoof(Dataset):\n",
    "    def __init__(self, dataframe, labels, path, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        self.labels = labels\n",
    "        self.path = path\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filepath = self.dataframe.iloc[idx]['path']\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = cv2.imread(os.path.join(self.path, filepath))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataframe.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T12:03:11.473454Z",
     "iopub.status.busy": "2023-04-16T12:03:11.472770Z",
     "iopub.status.idle": "2023-04-16T12:03:11.485141Z",
     "shell.execute_reply": "2023-04-16T12:03:11.483945Z",
     "shell.execute_reply.started": "2023-04-16T12:03:11.473420Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_train_augmentations(image_size_h, image_size_w):\n",
    "    return Compose([\n",
    "        Resize(image_size_h, image_size_w),\n",
    "        HorizontalFlip(p=0.5),\n",
    "        RandomBrightnessContrast(p=0.4, brightness_limit=0.25, contrast_limit=0.3),\n",
    "        RandomGamma(p=0.4),\n",
    "        CoarseDropout(p=0.1, max_holes=8, max_height=8, max_width=8),\n",
    "        GaussNoise(p=0.1, var_limit=(5.0, 50.0)),\n",
    "        ShiftScaleRotate(shift_limit=0.1, scale_limit=0.15, rotate_limit=45, p=0.8),\n",
    "        ImageCompression(quality_lower=80, quality_upper=100, p=0.4),\n",
    "        Normalize(\n",
    "            mean=mean_,\n",
    "            std=std_,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_val_augmentations(image_size_h, image_size_w):\n",
    "    return Compose([\n",
    "        Resize(image_size_h, image_size_w),\n",
    "        Normalize(\n",
    "            mean=mean_,\n",
    "            std=std_,\n",
    "        ),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "def preprocess_data(df):\n",
    "    train_df, val_df = train_test_split(df, random_state=128, test_size=0.2)\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le = le.fit(train_df['label'].values)\n",
    "    train_labels = le.transform(train_df['label'].values)\n",
    "    val_labels = le.transform(val_df['label'].values)\n",
    "    return train_df, val_df, train_labels, val_labels, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T12:03:12.200189Z",
     "iopub.status.busy": "2023-04-16T12:03:12.198755Z",
     "iopub.status.idle": "2023-04-16T12:03:12.211172Z",
     "shell.execute_reply": "2023-04-16T12:03:12.209954Z",
     "shell.execute_reply.started": "2023-04-16T12:03:12.200134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = df.label.nunique()\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T12:03:13.351839Z",
     "iopub.status.busy": "2023-04-16T12:03:13.351467Z",
     "iopub.status.idle": "2023-04-16T12:03:49.823879Z",
     "shell.execute_reply": "2023-04-16T12:03:49.821933Z",
     "shell.execute_reply.started": "2023-04-16T12:03:13.351805Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7903b00d0bb341a0904946f79aeba9be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3e9a52b4484e3191366b33f149a7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7744233172f541e6afc89da03de28641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2  train_loss 2.8371068636576333 train_f1 0.2604166666666667  val_loss 2.256637454032898  val_f1 0.41276041666666663\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12dd021464e4faea69e2390a3c19f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7644453ed18a4b26a3c6a0ab153c403a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2  train_loss 1.5582587122917175 train_f1 0.6536458333333334  val_loss 2.2271311283111572  val_f1 0.3910590277777778\n"
     ]
    }
   ],
   "source": [
    "def train_up():\n",
    "    BATCH_SIZE = 64\n",
    "    NUM_WORKERS = 8\n",
    "    IMAGE_SIZE_H, IMAGE_SIZE_W = 350, 350\n",
    "    N_EPOCHS = 20\n",
    "    device_ids = [0, 1]\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def get_train_loader():\n",
    "        albumentations_transform = get_train_augmentations(IMAGE_SIZE_H, IMAGE_SIZE_W)\n",
    "        train_data = Imagewoof(dataframe=train_df,\n",
    "                               labels=train_labels,\n",
    "                               path='input',\n",
    "                               transform=albumentations_transform)\n",
    "        train_loader = DataLoader(dataset=train_data,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  num_workers=NUM_WORKERS,\n",
    "                                  shuffle=True,\n",
    "                                  drop_last=True)\n",
    "        return train_loader\n",
    "    \n",
    "    albumentations_transform = get_train_augmentations(IMAGE_SIZE_H, IMAGE_SIZE_W)\n",
    "    albumentations_transform_validate = get_val_augmentations(IMAGE_SIZE_H, IMAGE_SIZE_W)\n",
    "    train_df, val_df, train_labels, val_labels, le = preprocess_data(df[:])\n",
    "\n",
    "    train_data = Imagewoof(dataframe=train_df,\n",
    "                           labels=train_labels,\n",
    "                           path='input',\n",
    "                           transform=albumentations_transform)\n",
    "    train_loader = DataLoader(dataset=train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              num_workers=NUM_WORKERS,\n",
    "                              shuffle=True,\n",
    "                              drop_last=True)\n",
    "\n",
    "    validate_data = Imagewoof(dataframe=val_df[:],\n",
    "                              labels=val_labels[:],\n",
    "                              path='input',\n",
    "                              transform=albumentations_transform_validate)\n",
    "    validate_loader = DataLoader(dataset=validate_data,\n",
    "                                 batch_size=BATCH_SIZE,\n",
    "                                 num_workers=NUM_WORKERS,\n",
    "                                 shuffle=False,\n",
    "                                 drop_last=False)\n",
    "\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.fc = nn.Linear(2048, n_classes)\n",
    "#     model = nn.DataParallel(model, device_ids=device_ids, output_device=device)\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.0003)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=200)\n",
    "\n",
    "    best_acc_val = 0\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "\n",
    "        train_loader = get_train_loader()\n",
    "        train_len = len(train_loader)\n",
    "        for i, (imgs, labels) in tqdm(enumerate(train_loader), total=train_len):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(imgs)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            pred = torch.argmax(torch.softmax(output, 1), 1).cpu().detach().numpy()\n",
    "            true = labels.cpu().numpy()\n",
    "            train_acc += f1_score(true, pred, average='micro')\n",
    "            scheduler.step(epoch + i / train_len)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        acc_val = 0\n",
    "        val_len = len(validate_loader)\n",
    "        for i, (imgs, labels) in tqdm(enumerate(validate_loader), total=val_len):\n",
    "            with torch.no_grad():\n",
    "                imgs_vaild, labels_vaild = imgs.to(device), labels.to(device)\n",
    "                output_test = model(imgs_vaild)\n",
    "                val_loss += criterion(output_test, labels_vaild).item()\n",
    "                pred = torch.argmax(torch.softmax(output_test, 1), 1).cpu().detach().numpy()\n",
    "                true = labels.cpu().numpy()\n",
    "                acc_val += f1_score(true, pred, average='micro')\n",
    "\n",
    "        avg_val_acc = acc_val / val_len\n",
    "\n",
    "        print(\n",
    "            f'Epoch {epoch}/{N_EPOCHS}  train_loss {train_loss / train_len} train_f1 {train_acc / train_len}  val_loss {val_loss / val_len}  val_f1 {avg_val_acc}')\n",
    "\n",
    "        torch.save(model.state_dict(), f'weight_{epoch}.pth')\n",
    "        if avg_val_acc > best_acc_val:\n",
    "            best_acc_val = avg_val_acc\n",
    "            torch.save(model.state_dict(), f'weight_best.pth')\n",
    "\n",
    "    return le\n",
    "\n",
    "le = train_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-15T10:25:41.065726Z",
     "iopub.status.busy": "2023-04-15T10:25:41.065322Z",
     "iopub.status.idle": "2023-04-15T10:25:41.081354Z",
     "shell.execute_reply": "2023-04-15T10:25:41.080362Z",
     "shell.execute_reply.started": "2023-04-15T10:25:41.065671Z"
    }
   },
   "outputs": [],
   "source": [
    "test['label'] = train.label.values[:test.shape[0]]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-15T10:29:00.369161Z",
     "iopub.status.busy": "2023-04-15T10:29:00.368772Z",
     "iopub.status.idle": "2023-04-15T10:29:18.160434Z",
     "shell.execute_reply": "2023-04-15T10:29:18.159323Z",
     "shell.execute_reply.started": "2023-04-15T10:29:00.369125Z"
    }
   },
   "outputs": [],
   "source": [
    "paths = ['/kaggle/working/weight_15.pth',\n",
    "        '/kaggle/working/weight_16.pth',\n",
    "         '/kaggle/working/weight_17.pth',\n",
    "         '/kaggle/working/weight_18.pth',\n",
    "         '/kaggle/working/weight_19.pth',\n",
    "         '/kaggle/working/weight_20.pth',\n",
    "         '/kaggle/working/weight_21.pth',\n",
    "         '/kaggle/working/weight_best.pth'\n",
    "        ]\n",
    "\n",
    "for path_weight_model in paths:\n",
    "    BATCH_SIZE = 64\n",
    "    NUM_WORKERS = 8\n",
    "    IMAGE_SIZE_H, IMAGE_SIZE_W = 350, 350\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    device_ids = [0, 1]\n",
    "\n",
    "    val_df = test[:]\n",
    "    val_labels = le.transform(val_df['label'].values)\n",
    "\n",
    "    albumentations_transform_validate = get_val_augmentations(IMAGE_SIZE_H, IMAGE_SIZE_W)\n",
    "\n",
    "    validate_data = Imagewoof(dataframe=val_df,\n",
    "                              labels=val_labels,\n",
    "                              path='input',\n",
    "                              transform=albumentations_transform_validate)\n",
    "    validate_loader = DataLoader(dataset=validate_data,\n",
    "                                 batch_size=BATCH_SIZE,\n",
    "                                 num_workers=NUM_WORKERS,\n",
    "                                 shuffle=False,\n",
    "                                 drop_last=False)\n",
    "\n",
    "\n",
    "    model = models.resnet50(pretrained=False)\n",
    "    model.fc = nn.Linear(2048, n_classes)\n",
    "    # model = nn.DataParallel(model, device_ids=device_ids, output_device=device)\n",
    "    checkpoint = torch.load(path_weight_model, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    pred_all = []\n",
    "    model.eval()\n",
    "    val_len = len(validate_loader)\n",
    "    for i, (imgs, labels) in tqdm(enumerate(validate_loader), total=val_len):\n",
    "        with torch.no_grad():\n",
    "            imgs_vaild, labels_vaild = imgs.to(device), labels.to(device)\n",
    "            output_test = model(imgs_vaild)\n",
    "            pred = torch.argmax(torch.softmax(output_test, 1), 1).cpu().detach().numpy()\n",
    "            pred_all.extend(list(pred))\n",
    "\n",
    "    test_ = test.copy()[:]\n",
    "    test_['label'] = le.inverse_transform(pred_all)\n",
    "    test_[['image_id', 'label']].to_csv(f'sub_{path_weight_model.split(\"/\")[-1][:-4]}_resnet50_22ep_64b_0003lr_350r_8020_128r.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для блендинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import sys\n",
    "# import os\n",
    "\n",
    "\n",
    "# df = pd.DataFrame()\n",
    "\n",
    "# for sub in os.listdir('submit'):\n",
    "#     df = df.append(pd.read_csv('submit/' + sub))\n",
    "\n",
    "# tmp = df.groupby('image_id', sort=False).label.agg(list).reset_index()\n",
    "# tmp.label = tmp.label.apply(lambda x: max(x, key=x.count))\n",
    "# tmp.to_csv('sub_blend_31.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
